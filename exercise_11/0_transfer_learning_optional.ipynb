{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0_transfer_learning_optional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pXjEQrk0eQ7E"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXHD-WZcNL-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAwovhFcNkIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pytorch-lightning==0.7.6 > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfv0DU6mNlXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd '/content/drive/My Drive/i2dl_exercises/exercise_11'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-Qo5nu2eQ7F"
      },
      "source": [
        "Transfer learning is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. Transfer learning allows one innovation to contribute to many others, and makes cross-applications possible. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6nMY34UDeQ7G"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1050/1*Z11P-CjNYWBofEbmGQrptA.png\"\n",
        "     alt=\"transfer learning\"\n",
        "     width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0WO4G5KBeQ7G"
      },
      "source": [
        "Besides, transfer learning can compensate for the problem of too little training data. Imagine you’re trying to build a deep learning model but don’t have much training data. Maybe you’re trying to identify a rare skin disease and only have 100 images. Meanwhile, someone else has trained an image recognition model on a 100,000 labeled photos of dogs and has managed to get 96 percent accuracy at classifying different breeds. These tasks don’t seem related, but that doesn’t mean the dog breed classifier is irrelevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3auwGA4BeQ7H"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gP1lSmb2eQ7H"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INcyIPoEM8Ck",
        "colab_type": "text"
      },
      "source": [
        "Here we import some necessary packages which you are already familiar with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ql_9m8-HeQ7I",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (4.8, 4.8) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fudu70OTeQ7N"
      },
      "source": [
        "### Get Device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jPigmsrM8Cv",
        "colab_type": "text"
      },
      "source": [
        "The default device for this notebook is CPU, you may also try GPU e.g. Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uk_p6y7JeQ7N",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQ05QKc7eQ7Q"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzDdwPczM8C3",
        "colab_type": "text"
      },
      "source": [
        "In this exercise, we use the CIFAR10 dataset for transfer learning.  \n",
        "However, we need to resize our input image shape to fit the model better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIG9RqjPeQ7R",
        "colab": {}
      },
      "source": [
        "# Set training image size. Cifar10 images are 32x32, ImageNet images are 224x224\n",
        "image_size = 64\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize((image_size, image_size), interpolation=2),\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize(mean=[0.49191375, 0.48235852, 0.44673872],\n",
        "                                      std=[0.24706447, 0.24346213, 0.26147554])])\n",
        "\n",
        "CIFAR_ROOT = \"../datasets/cifar10\"\n",
        "\n",
        "data = torchvision.datasets.ImageFolder(root=CIFAR_ROOT, transform=transform)\n",
        "print(\"Dataset contains %d images.\" % len(data))\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(data, [40000, 5000, 5000])\n",
        "\n",
        "dataset = (train_set, val_set, test_set,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KOP6Dv3EeQ7T"
      },
      "source": [
        "### Visualize Some Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-zzzeijeQ7T",
        "colab": {}
      },
      "source": [
        "sample_num = 5\n",
        "classes = os.listdir(CIFAR_ROOT)\n",
        "print(classes)\n",
        "\n",
        "for idx, c in enumerate(classes):\n",
        "    sampled_idx = torch.randint(1, 4000, (5,))\n",
        "    for i in range(sample_num):\n",
        "        plt.subplot(1, sample_num, i + 1)\n",
        "        image = Image.open(CIFAR_ROOT + \"/\" + c + \"/\" + str(sampled_idx[i].item()).zfill(4) + '.png')\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "npBBzEvAXic9"
      },
      "source": [
        "### Setup Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y-1DABlcXhls",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs --port 6008"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XyqwrCH0eQ7W"
      },
      "source": [
        "## Load the Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_MEcA62QW-Sc"
      },
      "source": [
        "In this notebook we use a pretrained mobilenet_v2 model [(Mark Sandler et. al)](https://arxiv.org/abs/1801.04381). The mobilenet_v2 is a mobile convolutional network with good performance. \n",
        "The mobilenet_v2 model contains 2 components: \n",
        "- __Conv feature extractor:__ Convolutional layers, ReLU-activations and BatchNorm to encode the visual features of an image\n",
        "- __Classification head:__ Dropout and fully-connected layer for classification.\n",
        "\n",
        "Here, the mobilenet_v2 provided by torchvision is trained on [(ImageNet)](http://www.image-net.org/), which has inputs of the shape 224x224. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z9D2ELIbW-Sd"
      },
      "source": [
        "<img src=\"https://pytorch.org/assets/images/mobilenet_v2_2.png\"\n",
        "     alt=\"mobilenet_v2\"\n",
        "     width=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OleYkQ4rW-Se"
      },
      "source": [
        "The main idea behind transfer learning for image classifiaction is that we can use the convolutional network for encoding the CIFAR10 images as the network was trained on a much larger dataset. We hope that the feature extraction generalizes well on CIFAR10. However, we have to re-train our specific classifier and a few high-level convolutional layers, because we have less and different classes than in the ImageNet dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHw4vYbaM8EM",
        "colab_type": "text"
      },
      "source": [
        "Luckily, PyTorch already provides a range of pretrained networks for various tasks like classification and object detection. You can check out the different models here: https://pytorch.org/docs/stable/torchvision/models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PdXol1EVeQ7X",
        "colab": {}
      },
      "source": [
        "# We first load the model and have a look at the different parts of the network\n",
        "\n",
        "# load the pretrained model\n",
        "pretrained_model = torchvision.models.mobilenet_v2(pretrained=True).cuda()\n",
        "\n",
        "# features\n",
        "print('Conv feature extractor:')\n",
        "print(pretrained_model.features)\n",
        "# classifier\n",
        "print('Classification head:')\n",
        "print(pretrained_model.classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHW5ing7M8FC",
        "colab_type": "text"
      },
      "source": [
        "Here we take a look at the network architecture with ```torchsummary```, in case you haven't used it before, download with ```pip install torchsummary```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tuxV5EmM8FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print a more thorough summary with the pretrained ImageNet input size 224x224\n",
        "import torchsummary\n",
        "\n",
        "torchsummary.summary(pretrained_model, (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA1aCQRqM8FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the following, we only make use of the pretrained convolutional layers. However, to save computation time,\n",
        "# we are not training our network on 224x224 images but 64x64. That is the beauty of convolution layers,\n",
        "# as they can be applied on any resolution.\n",
        "feature_extractor = pretrained_model.features\n",
        "\n",
        "torchsummary.summary(feature_extractor, (3, 64, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7TUmWj_BnIda"
      },
      "source": [
        "We build a new classifier ```PretrainedClassifier``` in which we would like to incorporate the pretrained feature extractor networks. To tailor the model to our sepcific task we have to build and re-train a new classifier as well as high-level convolutional layers. However, we want to freeze the weights of the low-level convolutional layers, as they extract simple features like edges and curves, and should not change during training. Therefore, we have to freeze the weights by disabling the ```requires_grad``` property of the parameters. In this way the feature extraction layers will not update!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGUIH1dTM8FL",
        "colab_type": "text"
      },
      "source": [
        "Note that we only use a single fully-connected layer in our self-defined Classification-head, no dropout layer needed, but can still get good results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kav9lTWIZdIh",
        "colab": {}
      },
      "source": [
        "class PretrainedClassifier(nn.Module): \n",
        "    def __init__(self, pretrained=True):\n",
        "        super(PretrainedClassifier, self).__init__()\n",
        "\n",
        "        if pretrained:\n",
        "            self.feature_extractor = feature_extractor\n",
        "            # We only freeze the parameters of the 10 low-level convolutional bottlenecks.\n",
        "            for param in self.feature_extractor[0:10].parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            self.feature_extractor = torchvision.models.mobilenet_v2(pretrained=False).features\n",
        "        \n",
        "        # Pooling is reliant on the input image size, e.g. for size 64 => (2, 2).\n",
        "        self.avg_pool = nn.AvgPool2d((2, 2))\n",
        "        \n",
        "        self.classifier = nn.Linear(in_features=1280, out_features=10, bias=True)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV2oIKlrM8FR",
        "colab_type": "text"
      },
      "source": [
        "## Training with Pytorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLCzT1xdM8FS",
        "colab_type": "text"
      },
      "source": [
        "In this exercise we train the model with Pytorch Lightning framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VkXWh4gngV-W"
      },
      "source": [
        "### Define Pytorch Lightning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "No719WK7f4he",
        "colab": {}
      },
      "source": [
        "from exercise_code.transfer_learning.MyPytorchModel import MyPytorchModel\n",
        "\n",
        "# Feel free to change the hyperparameters here!\n",
        "hparams = {\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 3e-4,\n",
        "}\n",
        "\n",
        "finetune_model = PretrainedClassifier(pretrained=True)\n",
        "\n",
        "model = MyPytorchModel(hparams, dataset, finetune_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hAtYMlU9oSD2"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klmxUd2UM8Fm",
        "colab_type": "text"
      },
      "source": [
        "The training may take 5-10 mins per epoch with CPU depending on your hardware, and 1-2 mins with GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O1-Rw_dmgssC",
        "colab": {}
      },
      "source": [
        "trainer = None\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=1,\n",
        "    gpus=1 if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "92QfLDakoVzy"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epeGrjgLg2EM",
        "colab": {}
      },
      "source": [
        "from exercise_code.transfer_learning.Util import test_model\n",
        "test_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bawoAi1mV_a"
      },
      "source": [
        "## Conclusion\n",
        "We can reach a high test accuracy i.e. about 85% after finetuning the pretrained mobilenet_v2 model. \n",
        "If you want you can play around and use other CNN backbones for your classifier. Feel free to add other networks from here: https://pytorch.org/docs/stable/torchvision/models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7_JvCC0ZdIz",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}